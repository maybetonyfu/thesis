% Chapter Template

\chapter{Haskell Type Checking} % Main chapter title

\label{chap:haskell-type-checking}

\graphicspath{{Figures/HaskellTypeChecking}}

In Chapter \ref{chap:introduction}, we briefly explored the history of programming languages with an emphasis on their practices in type checking and the paradigms they employ. This chapter focuses exclusively on Haskell, outlining why it is particularly well-suited for studying improvements in type error detection. We delve into the common techniques for performing type-checking on Haskell programs, specifically the Hindley-Milner type inference system and Algorithm W.

Furthermore, we examine various approaches that have been explored to provide better error messages, including Algorithm M, type error slicing, and interactive debugging. We also discuss key developments in the realm of constraint satisfiability, highlighting their significance to enhancing type error messages. Finally, we revisit the categorization of type errors, this time in light of the aforementioned techniques and tools.

\section{Why Haskell}

Haskell, introduced in 1990, is a functional programming language renowned for its enforcement of pure functional principles, lazy evaluation, and an expressive type system. The primary focus of my work is to develop type debugging systems for Haskell that leverage this expressive type system and address its limitations. Although we plan to extend our work to other languages, there are compelling reasons for initially focusing on Haskell.

\subsection{Haskell In Education}
As discussed in Chapter \ref{chap:introduction}, Haskell plays a significant role in undergraduate computer science education and was designed with this educational purpose in mind. Many textbooks targeting first-year computer science courses and introductions to functional programming recommend Haskell as a pedagogical tool \cite{Bird1998-kv, Davie1992-xv}. Proponents argue that Haskell serves as an ideal platform for teaching programming and rigorous reasoning due to its mathematical nature. Students often find that Haskell "elegantly admits solutions that are difficult to formulate in imperative languages," a sentiment echoed by computer scientist Edsger W. Dijkstra in a letter advocating for the use of Haskell for freshmen at the University of Texas, instead of Java.

Despite Dijkstra's enthusiasm, actual adoption in universities has been modest. One frequent challenge in teaching Haskell is helping students overcome programming errors \cite{Jun2000-yu, Tirronen2015-nr}. Some recommend using a simplified subset of Haskell's features to avoid the frustrations associated with complex type errors \cite{Heeren2003-mz}. Our research is motivated by both the desire to enhance Haskell's educational value and the real-world challenges associated with teaching the language.

\subsection{Haskell's special position in programming language research}

Although the full semantics of Haskell have never been formally defined \cite{Hudak2007-kn}, this has not deterred its use as a platform for programming language innovation or for meaningful academic contributions. Subsets of Haskell can be formalized for rigorous language study \cite{FaxEn2002-nd}. Haskell's dual presence in academia and the mainstream programming world uniquely positions it as a testing ground for new programming language features and ideas. Indeed, features such as Haskell's list comprehension have been adopted by languages like Python and Julia, and its generic type systems have influenced languages such as Java, C\#, and Rust.

Our research in Haskell benefits from the language's relatively small and well-studied specification, enabling rapid implementation of new ideas and swift feedback. We also enjoy support from Haskell's welcoming and active community, which helps guide our efforts towards improved correctness and usability.

\section{Hindley-Milner Type Inference and Algorithm W}

Type inference, also known as implicit typing, is a technique to reduce the number of occurrences of manually ascribing types. Almost all languages today employ a certain level of type inference. For instance, Java versions prior to 10 required users to explicitly declare variable types, which often led to verbosity and redundancy, as shown in Figure \ref{fig:example-java}. Java later introduced the var keyword (from version 10 onwards), allowing the type of a variable to be inferred at compile-time based on the assigned value \cite{noauthor_undated-an}.  

\begin{figure}[hbt]
  \includegraphics[width=\linewidth]{ExampleJava}
  \caption{
    \label{fig:example-java}
      An example of a typical Java program before and after introducing the \texttt{var} keyword. Before (Top), programmers have to annotate the type identical to the value initializer. After Java 10, this is solved using the local type inference with the \texttt{var} keyword (Bottom).
    }
\end{figure}

In language like Haskell and ML, not only is type inference applied, but its power to detect type error is hugely amplified by the use of the Hindley-Milner type inference  \cite{Damas1982-zw}. The Hindley-Milner Type System  named after its inventors Roger Hindley and Robin Milner, is a type system that can automatically infer the types of expressions in a language with no annotations required. It is a foundational part of the type system in many functional programming languages, including ML, Haskell, and Elm. The system provides polymorphic typing, meaning that a variable can be assigned multiple different types automatically based on its usage context, making it easier to write flexible, reusable code without compromising type safety. In many languages that use this system, it is proven that every expression will be assigned a most general type (principal type) based on its usage. 


In simpler type inference systems, such as the one used in the Java example (Fig \ref{fig:example-java}), type inference is local; it occurs within individual assignments and the compiler may raise errors if it cannot infer types from a single statement. In contrast, the Hindley-Milner system  employs a more global approach. It defers type constraints resolution and continues to assess the rest of the program, thereby increasing flexibility and reducing the immediateness of type errors.




\begin{figure}[hbt]
    \includegraphics[width=\linewidth]{HindleyMilner}
    \caption{
      \label{fig:hindley-milner}
        An illustration of Hindley Milner Type Checking Performed on a Lambda Expression, \todo{Expand this figure}}
\end{figure}

This sophisticated type inference mechanism found in the Hindley-Milner system underpins its wide adoption in the realm of functional programming. It exemplifies a shift towards more intelligent compilers that enhance developer productivity and code maintainability by abstracting the complexities of explicit type management.

\textbf{Algorithm W}  The foundational mechanism of the Hindley-Milner type system is Algorithm W, a method designed to deduce the most general types for each expression in a program. This algorithm starts by assigning a unique type variable to each expression. It then recursively analyzes the structure of the program, generating a set of type constraints by inspecting each syntax node—as shown in Figure \ref{fig:hindley-milner}. This process involves the creation of new type variables and the unification of these variables with others or with specific types.

Unification is a critical step: it attempts to make different type variables agree by finding a common type that satisfies all constraints. If unification is unsuccessful at any point, the type checking process halts immediately, indicating a type error. The algorithm report the expression where the last constraint was produced, but this is often reported as the sole source of the error.


Despite the seismic influence in type theory, and the conciseness of programming style it helps achieved,  the Hindley-Milner type system can be challenging in terms of usability. One notable drawback is how it handles error reporting. When type inference fails, the error messages can be cryptic and difficult to interpret. This is because the algorithm typically reports only the final constraint that led to the failure, omitting earlier but potentially relevant constraints. Unlike simpler cases in languages like Java—where a type error might be isolated to a single line—in a Hindley-Milner-based system, the underlying issue could be located anywhere in the program. This often leaves programmers scanning extensive sections of code to identify the root cause of the error. 

This aspect of Algorithm W highlights a trade-off between the power of the type inference offered by the Hindley-Milner system and usability, notably in terms of error diagnostics and clarity. This has prompted ongoing research into improving error reporting in systems based on this algorithm, seeking to make them more accessible and easier to use for programmers.

\textbf{Algorithm M} 
In response to the usability challenges posed by Algorithm W, an alternative approach known as Algorithm M was proposed \cite{Lee1998-fx}. This method modifies the direction of type inference from a bottom-up to a top-down process. By carrying constraints from the outer structure of the program to the substructures, Algorithm M allows for a more contextual analysis, resulting in more intuitive error messages in certain scenarios, as illustrated in Figure \ref{fig:algorithm-m-1}. 

\begin{figure}[hbt]
  \includegraphics[width=0.8\linewidth]{AlgorithmWM1.pdf}
  \caption{
    \label{fig:algorithm-m-1}
      An example where Algorithm M out-guessed Algorithm W, reporting a more plausible error location.}
\end{figure}


\begin{figure}[hbt]
  \includegraphics[width=0.8\linewidth]{AlgorithmWM2}
  \caption{
    \label{fig:algorithm-m-2}
    An example where Algorithm M may miss the correct location. It is more plausible here that \texttt{'0'} is a typo.}
\end{figure}


Despite its improvements in some cases, Algorithm M does not consistently outperform Algorithm W in terms of error clarity and can still produce misleading results, as shown in Figure \ref{fig:algorithm-m-2}. Both algorithms essentially face the same fundamental limitation: type inference is conducted step-by-step through unification, and once constraints are unified, they are discarded an unretrivable. Consequently, errors detected by these algorithms may not accurately reflect the root issues if multiple possible causes of types exist.

A lesson can be learned learned from both Algorithm W and M is the recognition that no inference method ensure that it will perfectly align with the programmer’s intentions. Rather than ambitiously pinpointing where the root cause may lie, a more realistic goal might be to represent type errors succinctly without making assumptions.


\section{Type Error Slicing}

Type error slicing is an advanced technique intended to enhance the meaningfulness of type error messages provided to programmers. This approach, referenced in works by Tip \cite{Tip2001-qn} and Haack \cite{Haack2004-fr}, improves upon traditional type inference methods by postponing the unification process until all relevant constraints have been established. Type error slicing incorporates two principal innovations:


\begin{enumerate}
  \item {
    \textbf{Labeled Constraints:}
    This involves assigning identifiable labels to constraints based on their locations within the program. These labels are subsequently used to trace and diagnose parts of the code associated with a type error, offering clearer insights into the origins of an error.
  }
  \item {
    \textbf{Minimal unsatisfiability analysis:} 
    This technique focuses on identifying the smallest set of conflicting constraints that cannot be satisfied simultaneously. This means finding the necessary evidence needed to reproduce the failed unification but nothing more than that. This approach significantly improve the diagnosis of type errors by avoiding the biases found in both Algorithms W and M.
  }
\end{enumerate}


\begin{figure}[hbt]
  \includegraphics[width=0.5\linewidth]{TypeErrorSlicing.pdf}
  \caption{
    \label{fig:type-error-slicing}
      An example of type error slicing}
\end{figure}

In contrast to conventional methods, type error slicing provides a comprehensive view of error locations, as demonstrated in Figure \ref{fig:type-error-slicing}. It allows programmers to understand type errors more thoroughly by presenting both sides of typing conflicts, thus facilitating a more informed debugging process.

Over time, type error slicing has become a preferred method for optimizing type errors. Innovations in this area include more efficient methods of finding minimal unsatisfiable subsets \cite{Liffiton2008-mx, Bailey2005-hi, Bacchus2015-of}. Type error slicing has also been enriched by exploring various underlying constraint languages that encode more complex type system features, such as those using SMT (Satisfiability Modulo Theories) \cite{Pavlinovic2015-ke} and Constraint Handling Rules \cite{Stuckey2003-pz}. These advancements have broadened the scope and applicability of type error slicing, making it a valuable tool for programming language development and error diagnosis.


\section{Interactive Type Debugging}

Traditional error diagnostic methods, such as the Minimal Unsatisfiable Subset (MUS) approach, have been instrumental in localizing single type errors by pinpointing a comprehensive yet minimal set of related code locations. Despite their utility, there are several key limitations associated with MUS-based localization and diagnosis:

\begin{figure}[hbt]
  \includegraphics[width=0.5\linewidth]{SlicingCounterExample}
  \caption{
    \label{fig:slicing-counter-example}
      An example where type error slicing essentially highlights every location in the program.}
\end{figure}

\begin{enumerate}
  \item {
    \textbf{Limited Code Reduction:} Although MUS-based error slicing can effectively narrow down the potentially defective code areas, studies such as Binkley's empirical analysis on program slicing \cite{binkley_empirical_2007} suggest that this method only reduces about 30\% of the code that needs to be examined to understand a type error. The minimal nature of MUS often prevents further reduction, which can be insufficient for complex errors as demonstrated in Figure \ref{fig:slicing-counter-example}, where virtually every location in the program could be implicated in the error.
  }

  \item{
    \textbf{Lack Of Enhanced Information Encoding:}  The existing MUS-based approaches might highlight critical error sites, but they often fail to capture the breadth of information required to fully understand and resolve type errors, especially in systems with complex type features.
  }
\end{enumerate}

To address these limitations, pioneering tools like Chameleon \cite{Stuckey2003-pz} have been developed. Initially introduced in the early 2000s, Chameleon served as a command-line tool aimed at improving type error reporting within the Haskell programming language. Unlike typical type-error slicing methods, Chameleon utilizes a more expressive constraint language—Constraint Handling Rules (CHR)—which enables the support of more flexible relational constraints tailored to advanced type-level features such as type classes and functional dependencies.

A key innovation of Chameleon is its adoption of interactive type debugging. This approach not only identifies potential error locations but also reveals that there could be multiple sets of potential types—most general unifiers—that could resolve the type issues present in the defected program. These types are traceable to distinct sets of code locations.

With interactive type debugging, programmers can query the type information of any possible resolution, effectively allowing programmers to ask counterfactual questions such as ``what would the type of the expression be if the type error is fixed". This interactive process significantly advances the programmers' understanding of type errors by allowing them to explore different resolution paths and better comprehend the type system's behaviors and expectations.

Interactive type debugging thus represents a significant evolution in the handling of type errors, offering a more dynamic and informative approach compared to static slicing methods. This development underscores a shift towards more user-centered diagnostics tools in programming, where clarity and interactivity play vital roles in problem-solving.

\begin{figure}[hbt]
  \includegraphics[width=0.8\linewidth]{ChameleonInteractive}
  \caption{
    \label{fig:chameleon-interactive}
      An example where type error slicing essentially highlights every location in the program.}
\end{figure}

\section{The Analysis Of An Unsatisfiable System}

One advantage of using a slicing-based approach is that many tools are available from the study of constraint satisfiability. Among them, a few important ones are the Minimal Unsatisfiable Subset (MUS), Minimal Correction Subset (MCS), and Maximal Satisfied Subset (MSS).  

\subsection{Minimal Unsatisfiable Subset}

MUS is the most commonly used tool in programming error analysis. Most program slicing-based tools \cite{Haack2004-fr, Pavlinovic2015-ke, Stuckey2003-pz} use MUS one way or another. Intuitively, MUS is the smallest subset of a constraints system that still remains infeasible. Infeasibility here simply means there are no ways to assign value to the logical variables. For an ill-typed program, this means finding a minimal set of locations that can explain the logical conflict of a type error. 

Formally,  a minimal unsatisfiable subset (MUS) $M$ of a constraint system $C$ is a subset $M \subseteq C$ such that $M$ is unsatisfiable and $ \forall{c} \in M : M \setminus \{c\}$ is satisfiable. An MUS can be seen as a minimal explanation of the infeasibility of the constraint system. MUSes have been used extensively, mostly in combination with programming slicing, as a means to explain type errors. A MUS of type system constraints encodes a path of reasoning connecting all evidence from one location of the conflict to another.


It needs to be made clear that, for a constraint system, multiple MUSes may exist. In the example in Fig \ref{fig:mus-example}, the constraint system contains 5 propositional constraints. Clearly, the whole system is infeasible. However, there are 3 possible MUSes in this system. We know that each MUS is minimal because removing any single constraint from a MUS will make it satisfiable. Conventionally, we use a shrink-based algorithm to find the MUS set. The basic idea is removing one constraint a time from the constraint set, until the remaining subset is satisfilbe. In this case, the last removed item must be a subset of MUS. And thus repeating the process until a MUS is derived. Although finding such a subset can be computationally expensive, it is useful because it represents the type error with comprehensive reasoning of how the error is inferred.



\section{The Analysis of an Unsatisfiable System}

A slicing-based approach benefits significantly from the established tools and techniques in constraint satisfiability. Key instruments in this domain include the Minimal Unsatisfiable Subset (MUS), Minimal Correction Subset (MCS), and Maximal Satisfiable Subset (MSS).

\subsection{Minimal Unsatisfiable Subset}

The MUS is a widely utilized tool in programming error analysis—it is employed in various program slicing-based tools \cite{Haack2004-fr, Pavlinovic2015-ke, Stuckey2003-pz}. The MUS represents the smallest possible subset of a constraints system that still remains unsatisfiable, meaning no values can be assigned to the logical variables without causing a conflict. This subset is crucial in determining the minimal set of code locations responsible for a type error.


Formally,  a minimal unsatisfiable subset (MUS) $M$ of a constraint system $C$ is a subset $M \subseteq C$ such that $M$ is unsatisfiable and $ \forall{c} \in M : M \setminus \{c\}$ is satisfiable.  An MUS provides a concise explanation for the infeasibility of a system, highlighting a logical pathway from one conflicting location to another.

It's important to note that an unsatisfiable constraint system may contain multiple MUSes, which complicates the analysis. For instance, consider a system with five propositional constraints depicted in Fig \ref{fig:mus-example}—the system is infeasible as a whole, but three potential MUSes can be identified. Each MUS is minimal since removing any single constraint results in a satisfiable system. Typically, a incremental algorithm is employed to discover a single MUS. This algorithm starts from an empty set, and adds one constraint at a time until the set is no longer satisfiable, indicating that the last added constraint must be an element of the MUS. 

\begin{figure}[hbt]
  \includegraphics[width=0.8\linewidth]{MUS}
  \caption{
    \label{fig:mus-example}
      An example of possible MUSes of a constraint system in propositional logic}
\end{figure}

\subsection{Minimal Correction Subset and Maximally Satisfiable Subset}

Beyond the MUS, the Minimal Correction Subset (MCS) represents the smallest group of constraints that, when removed, resolves the infeasibility (defect) of the system. Formally, a minimal correction set (MCS) $M$ of a constraint system $C$ is a subset $M \subseteq C$ such that $C \setminus M$ is satisfiable and $\forall{S} \subset M : C \setminus S$ is unsatisfiable. This "correction" subset is crucial for identifying minimal changes needed to rectify errors in a program. In the example (Fig. \ref{fig:mcs-example}), 4 MCSes can be found. Removing each of these will result in a satisfiable set of constraints. 


\begin{figure}[hbt]
  \includegraphics[width=0.8\linewidth]{MCS}
  \caption{
    \label{fig:mcs-example}
      An example of possible MCSes of a constraint system in propositional logic}
\end{figure}

The Maximal Satisfiable Subset (MSS) is the complement of an MCS. A maximal satisfiable subset (MSS) $M$ of a constraint system $C$ is a subset $M \subseteq C$ such that M is satisfiable and $\forall{c}\ in\ C \setminus M:M\cup\{c\}$ is unsatisfiable.. In practical terms, an MSS represents the largest portion of the constraint system that does not contribute to the type error, offering insights into the potential outcome of a working system after removing the defect. An example of MSSes in a constraint system can be seen in Fig \ref{fig:mss-example}.




\begin{figure}[hbt]
  \includegraphics[width=0.8\linewidth]{MSS}
  \caption{
    \label{fig:mss-example}
      An example of possible MSSes of a constraint system in propositional logic}
\end{figure}

\subsection{MUS Enumeration}

Since a system can harbor multiple MUSes and MCSes, enumerating these subsets reveals a deeper understanding of the different conflict sources and potential correction plans. Enumerating MUS/MCS is crucial for a comprehensive analysis in program analysis, hardware design, 

However, MUS enumeration is inherently challenging due to its computational demands. The most naive approach of finding all MUSes is to exhaust the power set of the constraint system, which is impractical for large systems. Advanced algorithms like MARCO~\cite{Liffiton2016-xi} and MUST~\cite{Bendik2020-pz} utilize heuristics to avoid traversing large blocks of subsets, enhancing efficiency and making the process viable even for complex systems.

This analysis forms a foundational aspect of our discussions on type error management in Chapter \ref{chap:goanna}, providing a structured approach to tackling programming errors through the lens of constraint satisfiability.


% \begin{figure}[hbt]
%   \includegraphics[width=\linewidth]{Subsets}
%   \caption{An example of generating constraints from Haskell program, and all the possible MUSes, MCSes, and MSSes can be acquired.}
% \end{figure}

\section{Three Classes of Type Error}
With the introduction of MUS, we can revisit the idea of three categories of type error we proposed in Chapter \ref{chap:introduction}. This categorization allows a formal study of the tools that are necessary to cover the information of a given type error. 

\subsection{Multi-step Type Error}
\begin{figure}[hbt]

  \includegraphics[width=0.5\linewidth]{Multi-Step-2}
  \caption{
    \label{fig:multi-step-2}
    A multi-step type error
  }
\end{figure}
Multiple-step type errors contain a chain of reasoning steps or a series of attempts to unify two logical terms. Multiple-step type error contains a single MUS. Each element of the MUS forms a singleton MCS. In the example of Fig \ref{fig:multi-step-2}, the MUS is the set of {A, B, C}. The MCSes are {A}, {B}, {C}. Removing any one of the MCSs will result in the program type check.

\subsection{Multi-witness Type Error}
\begin{figure}[hbt]
  \includegraphics[width=0.5\linewidth]{Multi-Witness-2}
  \caption{
    \label{fig:multi-witness-2}
    A multi-witness type error
  }
\end{figure}

A Multiple-witness type error occurs when one side of the conflict contains multiple locations (witnesses) suggesting the same typing assignment. If one such location is removed, the type error will remain. In the example (\ref{fig:multi-witness-2}), there are three MUSes: {A, B}, {A, C}, {A, D}. Therefore, this type of error cannot be succinctly represented by a single MUS. 

\subsection{Multi-party Type Error}
\begin{figure}[hbt]
  \includegraphics[width=0.5\linewidth]{Multi-Party-2}
  \caption{
    \label{fig:multi-party-2}
    A multi-party type error
  }
\end{figure}

A multiple-party type error is an error where multiple types of irreconcilable assignments can be obtained from locations in the source code. In the provided example  (\ref{fig:multi-party-2}), there are 3 MUS: {A, B}, {A,C}, {B,C}. Therefore, this type of error cannot be succinctly represented by a single MUS.

\begin{figure}[hbt]
  
  \includegraphics[width=\linewidth]{Compare}
  \caption{}
\end{figure}

\section{Conclusion}
In this chapter, we established a subset of the Haskell language by defining its syntax and typing rules. We explored two avenues to type-check a program in such language and obtain principle types: using the Hindley-Milner type system and using a constraint-based type system. In addition, we explored some type error analysis tools that are enabled by using a constraint-based type system and how these tools are applied to three different kinds of type errors. We will explore them in the next two chapters.
